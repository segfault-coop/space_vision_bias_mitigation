{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GPU Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset class for inpainting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageInpaintingDataset(Dataset):\n",
    "    def __init__(self, data_dir=\"../data/neo_usable\", mask_percentage=0.7, image_size=(256, 256), transform=None):\n",
    "        self.image_paths = [os.path.join(data_dir, fname) for fname in os.listdir(data_dir) if fname.endswith('.png')]\n",
    "        self.mask_percentage = mask_percentage\n",
    "        self.image_size = image_size\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, self.image_size)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        mask = np.ones(self.image_size, dtype=np.uint8)\n",
    "        mask_height = int(self.image_size[0] * self.mask_percentage)\n",
    "        mask[:mask_height, :] = 0\n",
    "        \n",
    "        mask = torch.tensor(mask).unsqueeze(0)\n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UNet architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(UNet, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diffusion process for noise addition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_diffusion(image, t, noise_schedule):\n",
    "    noise = torch.randn_like(image)  # Gaussian noise\n",
    "    noisy_image = torch.sqrt(1 - noise_schedule[t]) * image + torch.sqrt(noise_schedule[t]) * noise\n",
    "    return noisy_image\n",
    "\n",
    "# Loss function for diffusion model\n",
    "def diffusion_loss(pred_noise, noisy_image):\n",
    "    return nn.MSELoss()(pred_noise, noisy_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_diffusion_model(model, dataset, num_epochs=10, batch_size=16, timesteps=1000, learning_rate=1e-4):\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    noise_schedule = torch.linspace(1e-4, 0.02, timesteps).to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    \n",
    "    print(\"Starting training...\")\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for i, (images, masks) in enumerate(tqdm(dataloader)):\n",
    "            images = images.to(device).permute(0, 3, 1, 2)  # Convert to NCHW format\n",
    "            masks = masks.to(device)\n",
    "\n",
    "            t = torch.randint(0, timesteps, (images.size(0),), dtype=torch.long).to(device)\n",
    "            noisy_images = forward_diffusion(images, t, noise_schedule)\n",
    "\n",
    "            pred_noise = model(noisy_images)\n",
    "            loss = diffusion_loss(pred_noise, noisy_images)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Progress tracking\n",
    "            if i % 10 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(dataloader)}], Loss: {loss.item():.4f}\")\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], Average Loss: {running_loss / len(dataloader):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_reconstructed_images(model, dataset, output_dir=\"../data/neo_diffusion\"):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    dataloader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
    "    noise_schedule = torch.linspace(1e-4, 0.02, 1000).to(device)\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i, (image, mask) in enumerate(tqdm(dataloader)):\n",
    "            image = image.to(device).permute(0, 3, 1, 2)\n",
    "            mask = mask.to(device)\n",
    "\n",
    "            t = torch.randint(0, 1000, (1,), dtype=torch.long).to(device)\n",
    "            noisy_image = forward_diffusion(image, t, noise_schedule)\n",
    "            reconstructed_image = model(noisy_image)\n",
    "\n",
    "            reconstructed_image = reconstructed_image.cpu().permute(0, 2, 3, 1).numpy()[0]\n",
    "            reconstructed_image = (reconstructed_image * 255).astype(np.uint8)\n",
    "\n",
    "            output_path = os.path.join(output_dir, f\"reconstructed_{i}.png\")\n",
    "            cv2.imwrite(output_path, reconstructed_image)\n",
    "            print(f\"Saved: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load dataset and train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/514 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    dataset = ImageInpaintingDataset()  # Load usable images\n",
    "    model = UNet()  # Initialize the U-Net model\n",
    "    \n",
    "    # Train the model\n",
    "    train_diffusion_model(model, dataset, num_epochs=5)\n",
    "\n",
    "    # Save the reconstructed images\n",
    "    save_reconstructed_images(model, dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
